# app.py
from dotenv import load_dotenv
load_dotenv()  # .envï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰ã‚„ Streamlit Secrets ã®å€¤ã‚’ä½¿ã„ã¾ã™

import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

# --- ç”»é¢æƒ…å ± ---
st.set_page_config(page_title="å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ LLM", page_icon="ğŸ¤–")
st.title("å°‚é–€å®¶ãƒ¢ãƒ¼ãƒ‰ LLM ãƒ‡ãƒ¢")
st.write("""
ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ **LangChain** çµŒç”±ã§ **LLM** ã«æ¸¡ã—ã€\
é¸æŠã—ãŸ**å°‚é–€å®¶ã®è¦–ç‚¹**ã§å›ç­”ã—ã¾ã™ã€‚

**æ“ä½œæ–¹æ³•**  
1. ä¸‹ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§ã€Œå°‚é–€å®¶ã®ç¨®é¡ã€ã‚’é¸æŠ  
2. ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨ã€LLMã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™  
""")

# --- APIã‚­ãƒ¼ç¢ºèªï¼ˆ.env ã¾ãŸã¯ Streamlit Secretsï¼‰ ---
if not (os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY", None)):
    st.error("OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã¾ãŸã¯ï¼ˆStreamlit Cloudãªã‚‰ï¼‰Secretsã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- LLM ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆï¼ˆ1å›ã ã‘ï¼‰ ---
# â€» langchain-openai 0.2ç³»ã§ã¯ model= ã‚’æ¨å¥¨
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# --- å°‚é–€å®¶ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾©ï¼ˆA/B è‡ªç”±ã«ç·¨é›†å¯èƒ½ï¼‰ ---
EXPERT_PROMPTS = {
    "A: ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒ": (
        "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ¼ãƒã§ã™ã€‚æ—¥æœ¬ã®ãƒ“ã‚¸ãƒã‚¹æ–‡åŒ–ã¨ãƒ†ãƒƒã‚¯æ¥­ç•Œã®æ…£ç¿’ã«è©³ã—ãã€"
        "ç¾å®Ÿçš„ã§å®Ÿè¡Œå¯èƒ½ãªææ¡ˆã‚’è¡Œã„ã¾ã™ã€‚å›ç­”ã¯3ã¤ã®ç®‡æ¡æ›¸ãã¨ã€æœ€å¾Œã«ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’1è¡Œæ·»ãˆã¦ãã ã•ã„ã€‚"
    ),
    "B: æ „é¤Šå£«": (
        "ã‚ãªãŸã¯å›½å®¶è³‡æ ¼ã‚’æŒã¤æ „é¤Šå£«ã§ã™ã€‚ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ã¦ã€é£Ÿå“ä¾‹ã¨ãŠãŠã‚ˆãã®åˆ†é‡ã‚’äº¤ãˆãŸ"
        "å…·ä½“çš„ãªæ”¹å–„æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚æœ€å¾Œã«ã‚¢ãƒ¬ãƒ«ã‚®ãƒ¼é…æ…®ã®æ³¨æ„ç‚¹ã‚’1ã¤ä»˜ã‘ã¦ãã ã•ã„ã€‚"
    ),
}

# --- UI ---
expert = st.radio("å°‚é–€å®¶ã®ç¨®é¡ã‚’é¸æŠï¼š", list(EXPERT_PROMPTS.keys()))
user_text = st.text_area("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆï¼ˆç›¸è«‡å†…å®¹ãƒ»è³ªå•ãªã©ï¼‰", height=160, placeholder="ä¾‹ï¼šè»¢è·é¢æ¥ã§çŸ­æ‰€ã‚’ã©ã†ä¼ãˆã‚‹ã¹ãï¼Ÿ")

# --- èª²é¡Œè¦ä»¶ï¼šé–¢æ•°åŒ–ï¼ˆå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ & é¸æŠå€¤ â†’ å›ç­”ã‚’è¿”ã™ï¼‰ ---
def run_llm(input_text: str, selected_expert: str) -> str:
    """ãƒ©ã‚¸ã‚ªã®é¸æŠã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ LLM ã‚’å®Ÿè¡Œã—ã€å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™ã€‚"""
    system = SystemMessage(content=EXPERT_PROMPTS[selected_expert])
    user = HumanMessage(content=input_text)
    resp = llm.invoke([system, user])
    return resp.content

if st.button("é€ä¿¡"):
    if not user_text.strip():
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                answer = run_llm(user_text, expert)
                st.success("å›ç­”")
                st.write(answer)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
